# OpenAI Embedding Retrieval Experiment Configuration
# This configuration demonstrates how to use pre-computed OpenAI embeddings for retrieval

description: "OpenAI embedding-based retrieval using pre-computed embeddings"

models:
  - name: "openai_text_embedding_3_small"
    type: "openai_embedding"
    model_name_or_path: ""  # Not used for pre-computed embeddings
    device: "cpu"  # OpenAI embeddings don't require GPU
    batch_size: 32  # For similarity computation
    parameters:
      # Required: Directory containing embeddings
      embeddings_dir: "embeddings"
      
      # Required: OpenAI embedding model name (must match the directory structure)
      embedding_model: "text-embedding-3-small"
      
      # Optional: Dataset name (will be set automatically from dataset config)
      # dataset_name: "tydiqa_goldp_vietnamese"
      
      # Optional: Whether to normalize embeddings for cosine similarity (default: true)
      normalize_embeddings: true
      
      # Optional: Whether to cache embeddings in memory (default: true)
      cache_embeddings: true

datasets:
  - name: "tydiqa_goldp_vietnamese"
    type: "text"
    data_dir: "data/tydiqa_goldp_vietnamese"
    max_samples: null
    max_corpus_samples: null
    max_query_samples: null
    config_overrides: {}

evaluation:
  metrics: ["ndcg", "map", "recall", "precision"]
  k_values: [1, 3, 5, 10, 20, 50]
  relevance_threshold: 1
  include_per_query: true
  top_k: 1000
  save_run_file: true
  run_file_format: "trec"

output:
  output_dir: "../results"
  experiment_name: "openai_embedding_retrieval"
  save_models: false
  save_intermediate: true
  log_level: "INFO"
  overwrite: true

metadata:
  embedding_generation_info: "Embeddings were generated using embedding_tools/embed_dataset.py"
  notes: "Make sure embeddings exist before running this experiment. Run 'python embedding_tools/embed_dataset.py --help' for embedding generation instructions."
