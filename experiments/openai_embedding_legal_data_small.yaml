# OpenAI Embedding Models Comparison on Legal Data Small
# This configuration runs all 3 OpenAI embedding models on the legal_data_small dataset

description: "Comparative evaluation of all OpenAI embedding models on legal_data_small dataset"

models:
  - name: "openai_text_embedding_ada_002"
    type: "openai_embedding"
    model_name_or_path: ""  # Not used for pre-computed embeddings
    device: "cpu"  # OpenAI embeddings don't require GPU
    batch_size: 64  # For similarity computation
    parameters:
      # Required: Directory containing embeddings
      embeddings_dir: "embeddings"
      
      # Required: OpenAI embedding model name (must match the directory structure)
      embedding_model: "text-embedding-ada-002"
      
      # Optional: Whether to normalize embeddings for cosine similarity (default: true)
      normalize_embeddings: true
      
      # Optional: Whether to cache embeddings in memory (default: true)
      cache_embeddings: true

  - name: "openai_text_embedding_3_small"
    type: "openai_embedding"
    model_name_or_path: ""
    device: "cpu"
    batch_size: 64
    parameters:
      embeddings_dir: "embeddings"
      embedding_model: "text-embedding-3-small"
      normalize_embeddings: true
      cache_embeddings: true

  - name: "openai_text_embedding_3_large"
    type: "openai_embedding"
    model_name_or_path: ""
    device: "cpu"
    batch_size: 32  # Smaller batch for larger embeddings
    parameters:
      embeddings_dir: "embeddings"
      embedding_model: "text-embedding-3-large"
      normalize_embeddings: true
      cache_embeddings: true

datasets:
  - name: "legal_data_small"
    type: "text"
    data_dir: "data/legal_data_small"
    config_overrides:
      cache_enabled: true
      validation_enabled: true
      queries_file: "queries.jsonl"
      qrels_file: "qrels.txt"
      corpus_file: "corpus.jsonl"

evaluation:
  metrics: ["ndcg", "map", "recall", "precision", "mrr"]
  k_values: [1, 3, 5, 10, 20, 50, 100]
  relevance_threshold: 1
  include_per_query: true
  top_k: 1000
  save_run_file: true
  run_file_format: "trec"

output:
  output_dir: "./results/legal_data_small_openai_embeddings"
  experiment_name: "legal_data_small_openai_all_models"
  save_models: false
  save_intermediate: true
  log_level: "INFO"
  overwrite: true

metadata:
  experiment_type: "openai_embedding_comparison"
  models_compared: ["text-embedding-ada-002", "text-embedding-3-small", "text-embedding-3-large"]
  dataset: "legal_data_small"
  notes: |
    This experiment compares all 3 OpenAI embedding models on the legal_data_small dataset.
    
    Prerequisites - Make sure to generate embeddings for all models before running:
    python embedding_tools/embed_dataset.py --dataset_name legal_data_small --model text-embedding-ada-002
    python embedding_tools/embed_dataset.py --dataset_name legal_data_small --model text-embedding-3-small
    python embedding_tools/embed_dataset.py --dataset_name legal_data_small --model text-embedding-3-large
    
    Then run the experiment:
    python run_experiment.py experiments/openai_embedding_legal_data_small.yaml
