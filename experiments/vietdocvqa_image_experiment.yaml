# VietDocVQA Image Retrieval Experiment
# This configuration tests image retrieval models on Vietnamese document VQA data using original images

description: "VietDocVQA Image Retrieval Benchmark"

models:
  - name: "clip_multilingual"
    type: "image_retrieval"
    model_name_or_path: "sentence-transformers/clip-ViT-B-32-multilingual-v1"
    parameters:
      retrieval_method: "embedding"
      normalize_embeddings: true
      model_architecture: "clip"
      image_size: [224, 224]
      batch_size_images: 8
      batch_size_text: 32
    device: "cuda"
    max_seq_length: 77

  - name: "openai_clip"
    type: "image_retrieval"
    model_name_or_path: "openai/clip-vit-base-patch32"
    parameters:
      retrieval_method: "embedding"
      normalize_embeddings: true
      model_architecture: "clip"
      image_size: [224, 224]
      batch_size_images: 8
      batch_size_text: 32
      max_length: 77
    device: "cuda"
    max_seq_length: 77
  
datasets:
  - name: "vietdocvqa_images"
    type: "image"
    data_dir: "/home/hkduy/NewAI/new_bench/NewAIBench_VietDocVQAII_with_OCR"
    config_overrides:
      qrels_file: "qrels.jsonl"
      require_ocr_text: false  # Disable OCR text requirement to prevent filtering
      image_root_path: "/home/hkduy/NewAI/new_bench/NewAIBench_VietDocVQAII_with_OCR"
      image_root_path: "/home/hkduy/NewAI/new_bench/NewAIBench_VietDocVQAII_with_OCR"  # Set to dataset root since image paths include "images/" prefix
    max_samples: 1000  # Limit dataset for faster testing

evaluation:
  metrics: ["ndcg", "map", "recall", "precision", "mrr"]
  k_values: [1, 3, 5, 10, 20, 50]
  relevance_threshold: 1
  include_per_query: true
  top_k: 100
  save_run_file: true
  run_file_format: "trec"

output:
  output_dir: "./results/vietdocvqa_image_experiments"
  experiment_name: "vietdocvqa_image_retrieval"
  save_models: false
  save_intermediate: true
  log_level: "INFO"
  overwrite: true
