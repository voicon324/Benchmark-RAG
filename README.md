# NewAIBench - Framework ÄÃ¡nh GiÃ¡ Há»‡ Thá»‘ng Truy Váº¥n AI

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue.svg" alt="Python Version">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/Framework-PyTorch%20%7C%20Transformers-orange.svg" alt="Framework">
  <img src="https://img.shields.io/badge/Status-Active-brightgreen.svg" alt="Status">
</div>

---

## ğŸ¯ Tá»•ng Quan

**NewAIBench** lÃ  framework Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t toÃ n diá»‡n cho cÃ¡c há»‡ thá»‘ng truy váº¥n thÃ´ng tin (Information Retrieval) vá»›i trá»ng tÃ¢m lÃ  dá»¯ liá»‡u tiáº¿ng Viá»‡t. Framework há»— trá»£ Ä‘a dáº¡ng mÃ´ hÃ¬nh retrieval vÃ  cung cáº¥p cÃ¡c metrics Ä‘Ã¡nh giÃ¡ chuáº©n cho nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn.

### ğŸš€ TÃ­nh NÄƒng ChÃ­nh

- **ğŸ” Äa Dáº¡ng MÃ´ HÃ¬nh**: Sparse (BM25), Dense (BERT, Sentence-BERT), Vision (CLIP), Multimodal
- **ğŸ“Š Metrics ToÃ n Diá»‡n**: NDCG, MAP, Recall, Precision, MRR vá»›i k-values linh hoáº¡t
- **ğŸ—‚ï¸ Há»— Trá»£ Äa Dataset**: Text, Document Images, OCR, Multimodal
- **âš¡ Tá»‘i Æ¯u HÃ³a**: Parallel processing, GPU acceleration, caching
- **ğŸ”§ Cáº¥u HÃ¬nh Linh Hoáº¡t**: YAML configuration, CLI interface
- **ğŸ“ˆ BÃ¡o CÃ¡o Phong PhÃº**: CSV, JSON, visualization charts

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
NewAIBench/
â”œâ”€â”€ src/newaibench/           # Core framework
â”‚   â”œâ”€â”€ datasets/             # Dataset loaders  
â”‚   â”œâ”€â”€ models/               # Retrieval models
â”‚   â”œâ”€â”€ evaluation/           # Metrics & evaluation
â”‚   â”œâ”€â”€ experiment/           # Experiment runner
â”‚   â””â”€â”€ reporting/            # Results storage & reports
â”œâ”€â”€ experiments/              # Configuration files
â”œâ”€â”€ data/                     # Datasets
â”œâ”€â”€ embedding_tools/          # OpenAI embedding utilities
â””â”€â”€ results/                  # Experiment results
```

---

## ğŸ› ï¸ CÃ i Äáº·t

### 1. YÃªu Cáº§u Há»‡ Thá»‘ng

- **Python**: 3.8+ (khuyáº¿n nghá»‹ 3.12)
- **GPU**: CUDA-compatible (optional, tÄƒng tá»‘c Ä‘Ã¡ng ká»ƒ)
- **Memory**: 8GB+ RAM (tÃ¹y thuá»™c dataset size)

### 2. CÃ i Äáº·t MÃ´i TrÆ°á»ng

```bash
# Clone repository
git clone https://github.com/voicon324/NewAIBench.git
cd NewAIBench

# Táº¡o virtual environment
python3.12 -m venv python312_venv
source python312_venv/bin/activate

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 3. Cáº¥u HÃ¬nh OpenAI API (Optional)

```bash
# Äá»ƒ sá»­ dá»¥ng OpenAI embeddings
export OPENAI_API_KEY="sk-your-api-key-here"
```

---

## ğŸ“¦ Datasets

### ğŸ“¥ Táº£i Dataset

**[ğŸ”— Download All Datasets](https://drive.google.com/drive/folders/1IqBPR17x44kLosQTr54kaJ89yzBUSS7e?usp=sharing)**

```bash
# Táº¡o thÆ° má»¥c data
mkdir -p data

# Giáº£i nÃ©n datasets
unzip legal_data.zip -d data/
unzip NewAIBench_VietDocVQAII_with_OCR.zip -d data/
unzip tydiqa_goldp_vietnamese.zip -d data/
unzip UIT-ViQuAD2.0.zip -d data/
```

### ğŸ“Š Datasets Há»— Trá»£

| Dataset | Type | Size | Description |
|---------|------|------|-------------|
| **Legal Data** | Text | ~50K docs | VÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam |
| **VietDocVQA** | Multimodal | ~10K docs | TÃ i liá»‡u cÃ³ hÃ¬nh áº£nh + OCR |
| **TyDi QA Vietnamese** | Text | ~18K docs | Q&A Wikipedia tiáº¿ng Viá»‡t |
| **UIT-ViQuAD 2.0** | Text | ~23K docs | Reading comprehension |

---

## ğŸš€ Sá»­ Dá»¥ng Framework

### 1. Cháº¡y Experiment Tá»« Config File

```bash
# Cháº¡y experiment cÆ¡ báº£n
python run_experiment.py --config experiments/example.yaml

# Cháº¡y vá»›i ColVintern model
python run_experiment.py --config experiments/colvintern.yaml

# So sÃ¡nh OpenAI embeddings
python run_experiment.py --config experiments/openai_embedding_comparison.yaml
```

### 2. Cáº¥u HÃ¬nh Experiment (YAML)

```yaml
description: "Legal Data Retrieval Benchmark"

models:
  - name: "optimized_bm25"
    type: "optimized_sparse"
    parameters:
      k1: 1.6
      b: 0.75
      use_parallel_indexing: true
      use_caching: true
  
  - name: "vietnamese_sbert"
    type: "dense"
    model_name_or_path: "dangvantuan/vietnamese-embedding"
    parameters:
      normalize_embeddings: true
      use_ann_index: true

datasets:
  - name: "legal_data_small"
    type: "text"
    data_dir: "data/legal_data_small"

evaluation:
  metrics: ["ndcg", "map", "recall", "precision"]
  k_values: [1, 5, 10, 20, 50]
  top_k: 1000

output:
  output_dir: "./results"
  experiment_name: "legal_retrieval_benchmark"
```

### 3. Programmatic Usage

```python
from newaibench import (
    ExperimentRunner, 
    ExperimentConfig,
    TextDatasetLoader,
    OptimizedBM25Model
)

# Load dataset
config = DatasetConfig(data_dir="data/legal_data_small")
dataset = TextDatasetLoader(config)

# Initialize model
model = OptimizedBM25Model({
    'name': 'bm25_legal',
    'parameters': {'k1': 1.6, 'b': 0.75}
})

# Run evaluation
runner = ExperimentRunner(experiment_config)
results = runner.run()
```

---

## ğŸ”§ Táº¡o Embeddings vá»›i OpenAI

```bash
# Chuyá»ƒn Ä‘áº¿n embedding tools
cd embedding_tools

# Táº¡o embeddings cho dataset
python embed_dataset.py --dataset tydiqa_goldp_vietnamese --model text-embedding-3-large

# Sá»­ dá»¥ng embeddings trong experiment
python run_experiment.py --config experiments/openai_embedding.yaml
```

---

## ğŸ¯ CÃ¡c Loáº¡i MÃ´ HÃ¬nh Há»— Trá»£

### 1. Sparse Models
- **BM25**: Chuáº©n BM25 vá»›i tá»‘i Æ°u hÃ³a
- **Optimized BM25**: Parallel processing, GPU acceleration
- **Custom Sparse**: TÃ¹y chá»‰nh scoring function

### 2. Dense Models
- **Sentence-BERT**: Multilingual embeddings
- **Vietnamese BERT**: Specialized cho tiáº¿ng Viá»‡t
- **OpenAI Embeddings**: text-embedding-3-large/small
- **Custom Dense**: TÃ¹y chá»‰nh encoder architecture

### 3. Vision Models
- **CLIP**: Multimodal text-image retrieval
- **OCR-based**: Text extraction + dense retrieval
- **ColVintern**: Specialized Vietnamese document understanding

### 4. Multimodal Models
- **OCR + Dense**: Combine text extraction with embeddings
- **Vision + Text**: Joint multimodal representations

---

## ğŸ“Š Metrics ÄÃ¡nh GiÃ¡

### Supported Metrics

| Metric | Description | Best Use Case |
|--------|-------------|---------------|
| **NDCG@k** | Normalized Discounted Cumulative Gain | Ranked retrieval |
| **MAP@k** | Mean Average Precision | Overall precision |
| **Recall@k** | Recall at rank k | Coverage evaluation |
| **Precision@k** | Precision at rank k | Accuracy evaluation |
| **MRR** | Mean Reciprocal Rank | First relevant result |

### Customizable Parameters

```yaml
evaluation:
  metrics: ["ndcg", "map", "recall", "precision", "mrr"]
  k_values: [1, 3, 5, 10, 20, 50, 100]
  top_k: 1000
  relevance_threshold: 1
  include_per_query: true
```

---

## ğŸ“ˆ Káº¿t Quáº£ vÃ  BÃ¡o CÃ¡o

### 1. Cáº¥u TrÃºc Káº¿t Quáº£

```
results/
â”œâ”€â”€ experiment_name/
â”‚   â”œâ”€â”€ summary.json              # Tá»•ng quan metrics
â”‚   â”œâ”€â”€ detailed_results.json     # Chi tiáº¿t tá»«ng model
â”‚   â”œâ”€â”€ cost_analysis.json        # PhÃ¢n tÃ­ch chi phÃ­
â”‚   â””â”€â”€ runs/                     # Individual run data
```

### 2. Xuáº¥t BÃ¡o CÃ¡o CSV

```bash
# Chuyá»ƒn Ä‘á»•i káº¿t quáº£ thÃ nh CSV
python convert_results_to_csv.py --input results/

# Káº¿t quáº£ trong thÆ° má»¥c report_csv/
ls report_csv/
# tydiqa_goldp_vietnamese_recall_report.csv
# legal_data_recall_report.csv
```

### 3. VÃ­ Dá»¥ Káº¿t Quáº£

| Model | Dataset | Recall@1 | Recall@5 | Recall@10 | Execution Time |
|-------|---------|----------|----------|-----------|----------------|
| BM25 | Legal Data | 0.607 | 0.800 | 0.834 | 3.39s |
| Vietnamese BERT | Legal Data | 0.416 | 0.611 | 0.673 | 28.15s |
| OpenAI Embedding | Legal Data | 0.523 | 0.702 | 0.745 | 45.20s |

---

## ğŸ™ Acknowledgments

- **OpenAI**: Embedding APIs
- **Hugging Face**: Transformers library
- **Sentence-Transformers**: Dense retrieval models
- **BEIR**: Benchmark framework inspiration
- **Vietnamese NLP Community**: Dataset contributions

---